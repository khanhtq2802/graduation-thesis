{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict, Dataset, concatenate_datasets\n",
    "import random\n",
    "import string\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig, DataCollatorWithPadding, AdamW, get_scheduler, MarianMTModel, MarianTokenizer\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43851ebf80f841489a7e91729a323470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/724 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_files = {\n",
    "    \"test\": \"../data/test-for-llm - test-for-llm.csv\"\n",
    "}\n",
    "raw_dataset = load_dataset(\"csv\", data_files=data_files)\n",
    "raw_dataset = raw_dataset.remove_columns(['en_text', 'messages'])\n",
    "raw_dataset['test'] = raw_dataset[\"test\"].filter(lambda x: x[\"llm_labels\"] is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'llm_labels'],\n",
       "        num_rows: 214\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in raw_dataset:\n",
    "        data_dict = {\"labels\": [], \"llm_labels\": []}\n",
    "        for item in raw_dataset[name]:\n",
    "            aspect2label = {'all': 0, 'amn': 0, 'ch': 0, 'mgt': 0, 'nat': 0, 'ppl': 0}\n",
    "            labels = item['labels'].split()\n",
    "            for label in labels:\n",
    "                try:\n",
    "                    key, value = label.split('-')\n",
    "                except:\n",
    "                    print(\"Unknown label with text:\" + item['labels'])\n",
    "                if(key not in aspect2label or value not in ['0', '1', '2', '3']):\n",
    "                    raise Exception(\"Unknown label:\", label)\n",
    "                aspect2label[key] = int(value)\n",
    "            data_dict[\"labels\"].append('all-' + str(aspect2label['all']))\n",
    "            data_dict[\"labels\"].append('amn-' + str(aspect2label['amn']))\n",
    "            data_dict[\"labels\"].append('ch-' + str(aspect2label['ch']))\n",
    "            data_dict[\"labels\"].append('ppl-' + str(aspect2label['ppl']))\n",
    "            data_dict[\"labels\"].append('mgt-' + str(aspect2label['mgt']))\n",
    "            data_dict[\"labels\"].append('nat-' + str(aspect2label['nat']))\n",
    "            ################################################################\n",
    "            aspect2label = {'all': 0, 'amn': 0, 'ch': 0, 'mgt': 0, 'nat': 0, 'ppl': 0}\n",
    "            labels = item['llm_labels'].split()\n",
    "            for label in labels:\n",
    "                try:\n",
    "                    key, value = label.split('-')\n",
    "                except:\n",
    "                    print(\"Unknown label with text:\" + item['llm_labels'])\n",
    "                if(key not in aspect2label or value not in ['0', '1', '2', '3']):\n",
    "                    raise Exception(\"Unknown label:\", label)\n",
    "                aspect2label[key] = int(value)\n",
    "            data_dict[\"llm_labels\"].append('all-' + str(aspect2label['all']))\n",
    "            data_dict[\"llm_labels\"].append('amn-' + str(aspect2label['amn']))\n",
    "            data_dict[\"llm_labels\"].append('ch-' + str(aspect2label['ch']))\n",
    "            data_dict[\"llm_labels\"].append('ppl-' + str(aspect2label['ppl']))\n",
    "            data_dict[\"llm_labels\"].append('mgt-' + str(aspect2label['mgt']))\n",
    "            data_dict[\"llm_labels\"].append('nat-' + str(aspect2label['nat']))\n",
    "\n",
    "        raw_dataset[name] = Dataset.from_dict(DatasetDict(data_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': 'all-1', 'llm_labels': 'all-1'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all-0 precision: 0.8 recall: 0.3333333333333333 f1: 0.47058823529411764\n",
      "amn-0 precision: 0.7955801104972375 recall: 0.9230769230769231 f1: 0.85459940652819\n",
      "ch-0 precision: 0.8287671232876712 recall: 0.8175675675675675 f1: 0.8231292517006803\n",
      "mgt-0 precision: 0.9148936170212766 recall: 0.9297297297297298 f1: 0.9222520107238605\n",
      "nat-0 precision: 0.8602150537634409 recall: 0.9090909090909091 f1: 0.8839779005524862\n",
      "ppl-0 precision: 0.9704433497536946 recall: 0.9899497487437185 f1: 0.9800995024875622\n",
      "all-1 precision: 0.8166666666666667 recall: 0.98 f1: 0.890909090909091\n",
      "amn-1 precision: 0.47368421052631576 recall: 0.2647058823529412 f1: 0.339622641509434\n",
      "ch-1 precision: 0.3829787234042553 recall: 0.6 f1: 0.4675324675324675\n",
      "mgt-1 precision: 0.1 recall: 0.14285714285714285 f1: 0.11764705882352941\n",
      "nat-1 precision: 0.2916666666666667 recall: 0.25 f1: 0.2692307692307692\n",
      "ppl-1 precision: 0.7142857142857143 recall: 0.8333333333333334 f1: 0.7692307692307692\n",
      "all-2 precision: 0.7875 recall: 0.9130434782608695 f1: 0.8456375838926175\n",
      "amn-2 precision: 0.7142857142857143 recall: 0.5 f1: 0.588235294117647\n",
      "ch-2 precision: 0.7142857142857143 recall: 0.4838709677419355 f1: 0.5769230769230769\n",
      "mgt-2 precision: 0.5625 recall: 0.45 f1: 0.5\n",
      "nat-2 precision: 0.5 recall: 0.2 f1: 0.28571428571428575\n",
      "ppl-2 precision: 0.6666666666666666 recall: 0.25 f1: 0.36363636363636365\n",
      "all-3 precision: 0.5555555555555556 recall: 0.15151515151515152 f1: 0.2380952380952381\n",
      "amn-3 precision: 0 recall: 0 f1: 0\n",
      "ch-3 precision: 0 recall: 0 f1: 0\n",
      "mgt-3 precision: 0 recall: 0 f1: 0\n",
      "nat-3 precision: 0 recall: 0 f1: 0\n",
      "ppl-3 precision: 0 recall: 0 f1: 0\n",
      "Macro Precision: 0.5187489536111078\n",
      "Macro Recall: 0.4550864236501482\n",
      "Macro F1: 0.46612753945425767\n",
      "Accuracy: 0.8115264797507789\n",
      "{'all-0': 12, 'amn-0': 156, 'ch-0': 148, 'mgt-0': 185, 'nat-0': 176, 'ppl-0': 199, 'all-1': 100, 'amn-1': 34, 'ch-1': 30, 'mgt-1': 7, 'nat-1': 28, 'ppl-1': 6, 'all-2': 69, 'amn-2': 20, 'ch-2': 31, 'mgt-2': 20, 'nat-2': 10, 'ppl-2': 8, 'all-3': 33, 'amn-3': 4, 'ch-3': 5, 'mgt-3': 2, 'nat-3': 0, 'ppl-3': 1}\n"
     ]
    }
   ],
   "source": [
    "count_labels = {\n",
    "    \"all-0\": 0, \"amn-0\": 0, \"ch-0\": 0, \"mgt-0\": 0, \"nat-0\": 0, \"ppl-0\": 0,\n",
    "    \"all-1\": 0, \"amn-1\": 0, \"ch-1\": 0, \"mgt-1\": 0, \"nat-1\": 0, \"ppl-1\": 0,\n",
    "    \"all-2\": 0, \"amn-2\": 0, \"ch-2\": 0, \"mgt-2\": 0, \"nat-2\": 0, \"ppl-2\": 0,\n",
    "    \"all-3\": 0, \"amn-3\": 0, \"ch-3\": 0, \"mgt-3\": 0, \"nat-3\": 0, \"ppl-3\": 0,\n",
    "}\n",
    "\n",
    "count = {\n",
    "    \"true-positive\": {\n",
    "        \"all-0\": 0, \"amn-0\": 0, \"ch-0\": 0, \"mgt-0\": 0, \"nat-0\": 0, \"ppl-0\": 0,\n",
    "        \"all-1\": 0, \"amn-1\": 0, \"ch-1\": 0, \"mgt-1\": 0, \"nat-1\": 0, \"ppl-1\": 0,\n",
    "        \"all-2\": 0, \"amn-2\": 0, \"ch-2\": 0, \"mgt-2\": 0, \"nat-2\": 0, \"ppl-2\": 0,\n",
    "        \"all-3\": 0, \"amn-3\": 0, \"ch-3\": 0, \"mgt-3\": 0, \"nat-3\": 0, \"ppl-3\": 0,\n",
    "    },\n",
    "    \"false-positive\": {\n",
    "        \"all-0\": 0, \"amn-0\": 0, \"ch-0\": 0, \"mgt-0\": 0, \"nat-0\": 0, \"ppl-0\": 0,\n",
    "        \"all-1\": 0, \"amn-1\": 0, \"ch-1\": 0, \"mgt-1\": 0, \"nat-1\": 0, \"ppl-1\": 0,\n",
    "        \"all-2\": 0, \"amn-2\": 0, \"ch-2\": 0, \"mgt-2\": 0, \"nat-2\": 0, \"ppl-2\": 0,\n",
    "        \"all-3\": 0, \"amn-3\": 0, \"ch-3\": 0, \"mgt-3\": 0, \"nat-3\": 0, \"ppl-3\": 0,\n",
    "    },\n",
    "    \"false-negative\": {\n",
    "        \"all-0\": 0, \"amn-0\": 0, \"ch-0\": 0, \"mgt-0\": 0, \"nat-0\": 0, \"ppl-0\": 0,\n",
    "        \"all-1\": 0, \"amn-1\": 0, \"ch-1\": 0, \"mgt-1\": 0, \"nat-1\": 0, \"ppl-1\": 0,\n",
    "        \"all-2\": 0, \"amn-2\": 0, \"ch-2\": 0, \"mgt-2\": 0, \"nat-2\": 0, \"ppl-2\": 0,\n",
    "        \"all-3\": 0, \"amn-3\": 0, \"ch-3\": 0, \"mgt-3\": 0, \"nat-3\": 0, \"ppl-3\": 0,\n",
    "    },\n",
    "}\n",
    "\n",
    "total_instances = 0\n",
    "true_instances = 0\n",
    "\n",
    "# Assuming raw_dataset['test'] is a list of dictionaries containing 'labels' and 'llm_labels'\n",
    "for instances in raw_dataset['test']:\n",
    "    total_instances += 1\n",
    "    labels = instances['labels']\n",
    "    llm_labels = instances['llm_labels']\n",
    "    count_labels[labels] += 1\n",
    "\n",
    "    if labels == llm_labels:\n",
    "        true_instances += 1\n",
    "        count['true-positive'][labels] += 1\n",
    "    else:\n",
    "        count['false-negative'][labels] += 1\n",
    "        count['false-positive'][llm_labels] += 1\n",
    "\n",
    "macro_precision_sum = 0\n",
    "macro_recall_sum = 0\n",
    "macro_f1_sum = 0\n",
    "num_classes = len(count[\"false-negative\"])\n",
    "\n",
    "for type in count[\"false-negative\"]:\n",
    "    true_positive = count['true-positive'][type]\n",
    "    false_positive = count['false-positive'][type]\n",
    "    false_negative = count['false-negative'][type]\n",
    "\n",
    "    if true_positive == 0:\n",
    "        precision = 0\n",
    "        recall = 0\n",
    "        f1 = 0\n",
    "    else:\n",
    "        precision = true_positive / (true_positive + false_positive)\n",
    "        recall = true_positive / (true_positive + false_negative)\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    print(type, 'precision:', precision, 'recall:', recall, 'f1:', f1)\n",
    "    \n",
    "    macro_precision_sum += precision\n",
    "    macro_recall_sum += recall\n",
    "    macro_f1_sum += f1\n",
    "\n",
    "macro_precision = macro_precision_sum / num_classes\n",
    "macro_recall = macro_recall_sum / num_classes\n",
    "macro_f1 = macro_f1_sum / num_classes\n",
    "\n",
    "print('Macro Precision:', macro_precision)\n",
    "print('Macro Recall:', macro_recall)\n",
    "print('Macro F1:', macro_f1)\n",
    "print('Accuracy:', true_instances / total_instances)\n",
    "print(count_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
